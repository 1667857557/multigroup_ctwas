---
title: "Data preparation"
author: "Kaixuan Luo"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Data preparation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

## Overview

This document is a tutorial for preparing and preprocessing input data for cTWAS with summary statistics. We will use the `multigroup` version of the package, but the procedure below works for using a single prediction model, or multiple prediction models.

## Getting started

Install the `harmonize_test` branch of `cTWAS` package.
(it will be merged to the `multigroup` branch later)

```{r install_package, eval=FALSE}
remotes::install_github("xinhe-lab/ctwas", ref = "harmonize_test")
```

```{r, include=FALSE}
devtools::load_all("/home/kaixuan/projects/cTWAS_package/branches/ctwas/.")
```

Load the package and set the working directory where you want to perform the analysis.

```{r load_package, eval=FALSE}
library(ctwas)
```

```{r, eval=FALSE}
#set the working directory interactively
setwd("/project2/xinhe/shared_data/ctwas_tutorial")

#set the working directory when compiling this document with Knitr
knitr::opts_knit$set(root.dir = "/project2/xinhe/shared_data/ctwas_tutorial")
```

The inputs for the summary statistics version of cTWAS include GWAS summary statistics for variants, prediction models for genes in PredictDB format, and LD reference. 

We used the directories and files on the University of Chicago RCC cluster as examples. If you are at UChicago, you can load those data from RCC as below.

## GWAS z-scores

For this analysis, we will use summary statistics from a GWAS of LDL cholesterol in the UK Biobank. We will download the VCF from the IEU Open GWAS Project. 

```{r, eval=FALSE}
# set the working directory, download the summary statistics, and unzip the file.
dir.create("gwas_summary_stats")

system("wget https://gwas.mrcieu.ac.uk/files/ukb-d-30780_irnt/ukb-d-30780_irnt.vcf.gz -P gwas_summary_stats")
R.utils::gunzip("gwas_summary_stats/ukb-d-30780_irnt.vcf.gz")
```

Next, we will read the summary statistics. Then, we will compute the z-scores and format the input data. We will also collect the sample size, which will be useful later. We will save this output for convenience.

```{r, eval=FALSE}
# read the data using the VariantAnnotation package
z_snp <- VariantAnnotation::readVcf("gwas_summary_stats/ukb-d-30780_irnt.vcf")
z_snp <- as.data.frame(gwasvcf::vcf_to_tibble(z_snp))

# compute the z-scores
z_snp$Z <- z_snp$ES/z_snp$SE

# collect sample size (most frequent sample size for all variants)
gwas_n <- as.numeric(names(sort(table(z_snp$SS),decreasing=TRUE)[1]))

# subset the columns and format the column names
z_snp <- z_snp[,c("rsid", "ALT", "REF", "Z")]
colnames(z_snp) <- c("id", "A1", "A2", "z")

# drop multiallelic variants (id not unique)
z_snp <- z_snp[!(z_snp$id %in% z_snp$id[duplicated(z_snp$id)]),]

# save the formatted z-scores and GWAS sample size
saveRDS(z_snp, file="gwas_summary_stats/ukb-d-30780_irnt.RDS")
saveRDS(gwas_n, file="gwas_summary_stats/gwas_n.RDS")
```

After the previous step, we can load the data and look at the format. `z_snp` is a data frame, and each row is a variant. `A1` is the alternate allele, and `A2` is the reference allele. The sample size for this GWAS is `N=343,621`.

```{r load_z_snp, eval=FALSE}
z_snp <- readRDS("gwas_summary_stats/ukb-d-30780_irnt.RDS")
gwas_n <- readRDS("gwas_summary_stats/gwas_n.RDS")

head(z_snp)

# sample size
gwas_n 
```

## Prediction models

The `multigroup` version of cTWAS only accepts multiple sets of prediction models in PredictDB format. A single set of prediction models can still be specified in FUSION format, as in the `main` branch. See the section below on converting between FUSION and PredictDB weights for guidance on using multiple sets of FUSION weights. 

To specify weights in PredictDB format, provide the path to the `.db` file. Multiple prediction models can be specified by providing multiple paths as a vector.

For this analysis, we will use liver and subcutaneous adipose gene expression models trained on GTEx v8 in the PredictDB format. We will download both the prediction models (`.db`) and the covariances between variants in the prediction models (`.txt.gz`). The covariances can optionally be used during harmonization to recover strand ambiguous variants.

```{r, eval=FALSE}
# download the files
system("wget https://zenodo.org/record/3518299/files/mashr_eqtl.tar")

# extract to ./weights folder 
system("mkdir weights")
system("tar -xvf mashr_eqtl.tar -C weights")
system("rm mashr_eqtl.tar")
```

We also remove lncRNAs from the prediction models.

Process liver weights:

```{r, eval=FALSE}
library(RSQLite)

# specify the weight to remove lncRNA from
weight <- "weights/eqtl/mashr/mashr_Liver.db"

# read the PredictDB weights
sqlite <- dbDriver("SQLite")
db = dbConnect(sqlite, weight)
query <- function(...) dbGetQuery(db, ...)
weights_table <- query("select * from weights")
extra_table <- query("select * from extra")
dbDisconnect(db)

# subset to protein coding genes only
extra_table <-  extra_table[extra_table$gene_type=="protein_coding",,drop=F]
weights_table <- weights_table[weights_table$gene %in% extra_table$gene,]

# read and subset the covariances
weight_info <- read.table(gzfile(paste0(tools::file_path_sans_ext(weight), ".txt.gz")), header = T)
weight_info <- weight_info[weight_info$GENE %in% extra_table$gene,]

# write the .db file and the covariances
dir.create("weights_nolnc", showWarnings=F)

if (!file.exists("weights_nolnc/mashr_Liver_nolnc.db")){
  db <- dbConnect(sqlite, "weights_nolnc/mashr_Liver_nolnc.db")
  dbWriteTable(db, "extra", extra_table)
  dbWriteTable(db, "weights", weights_table)
  dbDisconnect(db)

  weight_info_gz <- gzfile("weights_nolnc/mashr_Liver_nolnc.txt.gz", "w")
  write.table(weight_info, weight_info_gz, sep=" ", quote=F, row.names=F, col.names=T)
  close(weight_info_gz)
}
```

Process adipose weights:

```{r, eval=FALSE}
library(RSQLite)

# specify the weight to remove lncRNA from
weight <- "weights/eqtl/mashr/mashr_Adipose_Subcutaneous.db"

# read the PredictDB weights
sqlite <- dbDriver("SQLite")
db = dbConnect(sqlite, weight)
query <- function(...) dbGetQuery(db, ...)
weights_table <- query("select * from weights")
extra_table <- query("select * from extra")
dbDisconnect(db)

# subset to protein coding genes only
extra_table <-  extra_table[extra_table$gene_type=="protein_coding",,drop=F]
weights_table <- weights_table[weights_table$gene %in% extra_table$gene,]

# read and subset the covariances
weight_info <- read.table(gzfile(paste0(tools::file_path_sans_ext(weight), ".txt.gz")), header = T)
weight_info <- weight_info[weight_info$GENE %in% extra_table$gene,]

# write the .db file and the covariances
dir.create("weights_nolnc", showWarnings=F)

if (!file.exists("weights_nolnc/mashr_Adipose_Subcutaneous_nolnc.db")){
  db <- dbConnect(sqlite, "weights_nolnc/mashr_Adipose_Subcutaneous_nolnc.db")
  dbWriteTable(db, "extra", extra_table)
  dbWriteTable(db, "weights", weights_table)
  dbDisconnect(db)

  weight_info_gz <- gzfile("weights_nolnc/mashr_Adipose_Subcutaneous_nolnc.txt.gz", "w")
  write.table(weight_info, weight_info_gz, sep=" ", quote=F, row.names=F, col.names=T)
  close(weight_info_gz)
}

rm(extra_table, weight_info, weights_table, weight_info_gz, sqlite, db)
```

We specify these processed prediction models as a vector of paths:

```{r, eval=FALSE}
weight <- c("weights_nolnc/mashr_Liver_nolnc.db", "weights_nolnc/mashr_Adipose_Subcutaneous_nolnc.db")
stopifnot(file.exists(weight))
```

## Converting between FUSION and PredictDB format

Because multiple sets of prediction models can only be specified in PredictDB format, it may be necessary to convert FUSION format weights to PredictDB format. See Jing's code for converting between FUSION and PredictDB weights.

PredictDB weights assume that variant genotypes are not standardized before imputation, but our implementation assumes standardized variant genotypes. For this reason, PredictDB weights are be scaled by genotype variance before imputing gene expression by default. If converting from FUSION to PredictDB format, the weights are already on the standardized scale, and scaling should be turned off using the option `scale_by_ld_variance=F` in the `impute_expr_z` function.

## LD reference and regions

LD reference information can be provided to cTWAS as either individual-level genotype data (in PLINK format), or as genetic correlation matrices (termed "R matrices") for regions that are approximately LD-independent. These regions must also be specified, regardless of how the LD reference information is provided.

We will use the regions and LD matrices specified in the user guide for the `main` branch of cTWAS.

```{r}
ld_R_dir <- "/project2/mstephens/wcrouse/UKB_LDR_0.1/"
```

## Data harmonization and preprocessing 

These inputs should be harmonized prior to analysis (i.e. the reference and alternative alleles for each variant should match across all three data sources). 

### Harmonizing GWAS z-scores and LD reference and LD mismatch diagnoisis

This step will harmonize GWAS z-scores and LD reference, then perform LD mismatch diagnoisis using SuSiE RSS,
and flip signs for z-scores with allele flipping issues.
```{r, eval=FALSE}
outputdir <- "multigroup/processed_data/"
dir.create(outputdir, showWarnings=F, recursive=T)
outname <- "example"

# number of cores to parallelize regions for LD mismatch diagnoisis
ncore <- 6

# perform the harmonization and LD mismatch diagnosis of z-scores 
# if chr is specified, it will only run for those chromosomes; otherwise, run all chromosomes
res <- preprocess_z_ld(z_snp = z_snp,
                       ld_R_dir = ld_R_dir,
                       chr = 22, 
                       ld_regions = "EUR",
                       ld_regions_version = "b38",
                       filestem = "ukb_b38_0.1",
                       gwas_n = gwas_n,
                       outputdir = outputdir,
                       outname = outname,
                       detect_ld_mismatch = TRUE, # If TRUE, detect LD mismatches using SuSiE RSS
                       flip_allele = TRUE, # If TRUE, flip z-scores with allele flipping
                       ncore = ncore)
```

The LD mismatch diagnosis procedure is quite time consuming. 
If you don't want to perform the LD mismatch diagnosis step, you can set `detect_ld_mismatch = FALSE`. 

```{r, eval=FALSE, include=FALSE}
outputdir <- "multigroup/processed_data/"
dir.create(outputdir, showWarnings=F, recursive=T)
outname <- "example"

# perform the harmonization and LD mismatch diagnosis of z-scores 
# if chr is specified, it will only run for those chromosomes; otherwise, run all chromosomes
res <- preprocess_z_ld(z_snp = z_snp,
                       ld_R_dir = ld_R_dir,
                       ld_regions = "EUR",
                       ld_regions_version = "b38",
                       filestem = "ukb_b38_0.1",
                       gwas_n = gwas_n,
                       outputdir = outputdir,
                       outname = outname,
                       detect_ld_mismatch = FALSE)
```


### Harmonizing prediction models and LD reference

Here we harmonize the PredictDB prediction models and LD reference before the cTWAS analysis. Harmonization only needs to be done once per combination of prediction models and LD reference. The output is a harmonized `.db` file in the output directory.

`strand_ambig_action` gives options to harmonize strand ambiguous variants (A/T, G/C) between the prediction models and LD reference. "drop" (default) removes the ambiguous variant from the prediction models. "none" treats the variant as unambiguous, flipping the weights to match the LD reference and then taking no additional action. "recover" uses a procedure to recover strand ambiguous variants. This procedure compares correlations between variants in the LD reference and prediction models, and it can only be used with PredictDB format prediction models, which include this information.

_We do not return the harmonized covariances between variants in the prediction models (`.txt.gz`)._

Harmonize the liver prediction model: 

```{r, eval=FALSE}
weight_dir <- "multigroup/processed_data/weights_nolnc/"
res <- preprocess_wgt_ld(weight = "weights_nolnc/mashr_Liver_nolnc.db",
                         ld_R_dir = ld_R_dir,
                         outputdir = weight_dir,
                         outname = "mashr_Liver_nolnc_harmonized",
                         strand_ambig_action = "drop")
rm(res)
```

Harmonize the PredictDB adipose prediction model:

```{r, eval=FALSE}
res <- preprocess_wgt_ld(weight = "weights_nolnc/mashr_Adipose_Subcutaneous_nolnc.db",
                         ld_R_dir = ld_R_dir,
                         outputdir = weight_dir,
                         outname = "mashr_Adipose_Subcutaneous_nolnc_harmonized",
                         strand_ambig_action = "drop")
rm(res)
```

## Imputing gene z-scores

After we have done data harmonization and preprocessing, we specify the harmonized weights as a vector and impute the gene z-scores. 

To impute gene z-scores genome-wide, we specify the GWAS summary statistics, both the PredictDB liver and adipose weights, and the LD reference matrices. 

If specifying only a single `.db` file (or a single set of FUSION weights), the output of this function using the `multigroup` branch is identical to the output using the `main` branch. If specifying more than one `.db` file, the gene names will have the name of the corresponding `.db` file appended after the gene name, e.g. "gene1|mashr_Liver_nolnc", but otherwise the output is the same.

Here, we impute gene z-scores for individual chromosomes using multiple cores, and then combining the results:

```{r, eval=FALSE}
outputdir <- "multigroup/processed_data/"
weight_dir <- "multigroup/processed_data/weights_nolnc/"

# load processed z_snp file
load(file = file.path(outputdir, paste0(outname, ".harmonized.z_snp.Rd")))

# processed prediction models
weight <- c(file.path(weight_dir, "mashr_Liver_nolnc_harmonized.db"), 
            file.path(weight_dir, "mashr_Adipose_Subcutaneous_nolnc_harmonized.db"))
stopifnot(file.exists(weight))

# impute gene z-scores by chromosome
ncore <- 6
outname <- "example"

for (i in 1:22){
  if (!file.exists(file.path(outputdir, paste0(outname, "_chr", i, ".expr.gz")))){
    cat("Imputing gene z-scores in chr", i, "\n")
    res <- impute_expr_z(z_snp = z_snp,
                         weight = weight,
                         ld_R_dir = ld_R_dir,
                         outputdir = outputdir,
                         outname = outname,
                         chrom=i,
                         ncore=ncore)
  }
}

# combine the imputed gene z-scores
z_gene <- list()
for (i in 1:22){
  load(file.path(outputdir, paste0(outname, "_chr", i, ".exprqc.Rd")))
  z_gene[[i]] <- z_gene_chr
}
z_gene <- do.call(rbind, z_gene)
rownames(z_gene) <- NULL
save(z_gene, file = file.path(outputdir, paste0(outname, "_z_gene.Rd")))

head(z_gene)

rm(qclist, wgtlist, z_gene_chr)
```

