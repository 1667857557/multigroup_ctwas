---
title: "Using cTWAS with summary statistics for a single locus"
author: "Kaixuan Luo"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using cTWAS with summary statistics for a single locus}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      eval = TRUE,
                      fig.width = 6,
                      fig.height = 4,
                      fig.align = "center",
                      fig.cap = "&nbsp;",
                      dpi = 120)
```


This document demonstrates how to use the summary statistics version of cTWAS using tutorial data from an example locus. 

## Getting started

Install `cTWAS` package

```{r install_package, eval=FALSE}
remotes::install_github("xinhe-lab/ctwas", ref = "multigroup_test")
```

Load `cTWAS` package

```{r load_package}
# library(ctwas)
devtools::load_all("~/projects/cTWAS_package/multigroup_test/ctwas")
```

## Preparing the input data

The inputs for the summary statistics version of cTWAS include GWAS summary statistics for variants, prediction models for genes, and LD reference. 

We used the directories and files on the University of Chicago RCC cluster as examples. If you are at UChicago, you can load those data from RCC as below.

### GWAS z-scores

For this analysis, we will use summary statistics from a GWAS of LDL cholesterol in the UK Biobank. We will download the VCF from the IEU Open GWAS Project. 

```{r, eval=FALSE}
# set the working directory, download the summary statistics, and unzip the file.
dir.create("/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/gwas_summary_stats")

system("wget https://gwas.mrcieu.ac.uk/files/ukb-d-30780_irnt/ukb-d-30780_irnt.vcf.gz -P gwas_summary_stats")
R.utils::gunzip("gwas_summary_stats/ukb-d-30780_irnt.vcf.gz")
```

Next, we will read the summary statistics. Then, we will compute the z-scores and format the input data. We will also collect the sample size, which will be useful later. We will save this output for convenience.

```{r, eval=FALSE}
# read the data using the VariantAnnotation package
z_snp <- VariantAnnotation::readVcf("/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt.vcf")
z_snp <- as.data.frame(gwasvcf::vcf_to_tibble(z_snp))

# compute the z-scores
z_snp$Z <- z_snp$ES/z_snp$SE

# collect sample size (most frequent sample size for all variants)
gwas_n <- as.numeric(names(sort(table(z_snp$SS),decreasing=TRUE)[1]))

# subset the columns and format the column names
z_snp <- z_snp[,c("rsid", "ALT", "REF", "Z")]
colnames(z_snp) <- c("id", "A1", "A2", "z")

# drop multiallelic variants (id not unique)
z_snp <- z_snp[!(z_snp$id %in% z_snp$id[duplicated(z_snp$id)]),]

# save the formatted z-scores and GWAS sample size
saveRDS(z_snp, file="/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt.RDS")
saveRDS(gwas_n, file="/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/gwas_summary_stats/gwas_n.RDS")
```

After the previous step, we can load the data and look at the format. 
`z_snp` is a data frame, and each row is a variant. `A1` is the alternate allele, and `A2` is the reference allele. The sample size for this GWAS is `N=343,621`.

```{r load_z_snp}
z_snp <- readRDS("/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt.RDS")
gwas_n <- readRDS("/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/gwas_summary_stats/gwas_n.RDS")

head(z_snp)

# sample size
gwas_n
```

### Prediction models

We use the prediction models in PredictDB format. 
Please check [PredictDB](http://predictdb.org/) for the format of PredictDB weights. To specify weights in PredictDB format, provide the path to the `.db` file. 

For this analysis, we will use liver gene expression models trained on GTEx v8 in the PredictDB format. We will download both the prediction models (`.db`) and the covariances between variants in the prediction models (`.txt.gz`). 

```{r, eval=FALSE}
# download the files
system("wget https://zenodo.org/record/3518299/files/mashr_eqtl.tar")

# extract to ./weights folder 
system("mkdir weights")
system("tar -xvf mashr_eqtl.tar -C weights")
system("rm mashr_eqtl.tar")
```

In the paper, we used PredictDB models for liver gene expression. 

```{r PredictDB_weight}
weight <- "/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/weights/eqtl/mashr/mashr_Liver.db"
```

### LD reference and regions

#### Defining regions

```{r region_info}
region_file <- system.file("extdata/ldetect", "EUR.b38.bed", package = "ctwas")
region_info <- read.table(region_file, header = TRUE)
colnames(region_info)[1:3] <- c("chrom", "start", "stop")
region_info$chrom <- as.numeric(gsub("chr", "", region_info$chrom))
region_info$region_tag <- paste0(region_info$chr, ":", region_info$start, "-", region_info$stop)

ld_R_dir <- "/project2/mstephens/wcrouse/UKB_LDR_0.1"
filestem <- "ukb_b38_0.1"
ld_filestem <- sprintf("%s_chr%s.R_snp.%s_%s", filestem, region_info$chrom, region_info$start, region_info$stop)
region_info$LD_matrix <- file.path(ld_R_dir, paste0(ld_filestem, ".RDS"))
region_info$SNP_info <- file.path(ld_R_dir, paste0(ld_filestem, ".Rvar"))

region_info[1:3,]
```

Here we focus on an example region containing the HPR locus using b38 European region file, which is included in the package.

```{r example_region}
# select example region
region_tag <- "16:71020125-72901251"
region_info <- region_info[region_info$region_tag == region_tag,]
region_info
```

#### LD matrices

To use LD matrices for the LD reference, provide a directory containing all of the `.RDS` matrix files and matching `.Rvar` variant information files. 

The complete LD matrices of European individuals from UK Biobank can be downloaded [here](https://uchicago.box.com/s/jqocacd2fulskmhoqnasrknbt59x3xkn). On the University of Chicago RCC cluster, the b38 reference is available at `/project2/mstephens/wcrouse/UKB_LDR_0.1/` and the b37 reference is available at `/project2/mstephens/wcrouse/UKB_LDR_0.1_b37/`.

We illustrated below how cTWAS uses the LD matrices. We have included an LD matrix for the HPR locus that we analyzed in the paper as part of the package. The complete LD matrix for this region was too large to include in the package, so we include only half of the variants at this locus, including the ones needed for the prediction models at this locus. 

```{r, include=FALSE, eval=FALSE}
# We obtained the example LD matrix using the following code
R_snp <- readRDS("/project2/mstephens/wcrouse/UKB_LDR_0.1/ukb_b38_0.1_chr16.R_snp.71020125_72901251.RDS")
R_snp_info <- read.table("/project2/mstephens/wcrouse/UKB_LDR_0.1/ukb_b38_0.1_chr16.R_snp.71020125_72901251.Rvar", header=T)

set.seed(3724598)
keep_index <- as.logical(rbinom(nrow(R_snp_info), 1 ,0.5)) | R_snp_info$id %in% weights_table$rsid

R_snp_info <- R_snp_info[keep_index,]
R_snp <- R_snp[keep_index, keep_index]

saveRDS(R_snp, file="example_locus_chr16.R_snp.71020125_72901251.RDS")
write.table(R_snp_info, file="example_locus_chr16.R_snp.71020125_72901251.Rvar", sep="\t", col.names=T, row.names=F, quote=F)
```

This example LD matrix can be loaded directly from the package:

```{r}
ld_R_dir <- system.file("extdata/ld_matrices", package = "ctwas")
list.files(ld_R_dir)
```

The `.RDS` file is [R .RDS format](https://www.rdocumentation.org/packages/base/versions/3.3.2/topics/readRDS?tap_a=5644-dce66f&tap_s=10907-287229). It stores the LD correlation matrix for a region (a $p \times p$ matrix, $p$ is the number of variants in the region). We require that for each `.RDS` file, in the same directory, there is a corresponding file with the same stem but ending with the suffix `.Rvar`. This `.Rvar` files includes variant information for the region, and the order of its rows must match the order of rows and columns in the `.RDS` file. The format of these files is:

```{r}
# correlation matrix
R_snp <- readRDS(system.file("extdata/ld_matrices", "example_locus_chr16.R_snp.71020125_72901251.RDS", package = "ctwas"))
R_snp[1:5,1:5]

# variant info
R_snp_info <- read.table(system.file("extdata/ld_matrices", "example_locus_chr16.R_snp.71020125_72901251.Rvar", package = "ctwas"), header=T)
R_snp_info[1:5,]
```

## Running cTWAS at a single locus

We subset the GWAS z-scores to only the variants in this region:

```{r, eval=FALSE}
z_snp_subset <- z_snp[z_snp$id %in% R_snp_info$id,]
saveRDS(z_snp_subset, file="gwas_summary_stats/ukb-d-30780_irnt_subset.RDS")
```

We've also included this file as part of the package:

```{r}
z_snp_subset <- readRDS(system.file("extdata/summary_stats", "ukb-d-30780_irnt_subset.RDS", package = "ctwas"))
```

### Data harmonization

These inputs should be harmonized prior to cTWAS analysis (i.e. the reference and alternative alleles for each variant should match across all three data sources). 

#### Harmonizing GWAS z-scores and LD reference and detect LD mismatches

The `process_z()` function first harmonizes GWAS z-scores and LD reference based on the included allele information, 
then performs LD mismatch diagnosis using the `kriging_rss()` function from SuSiE RSS, 
and flips signs for variants detected with allele flipping issues. 
Note, the LD mismatch diagnosis procedure can be time consuming, and we don't have LD mismatch here as the GWAS was from UK Biobank data, 
so we turn off `detect_ld_mismatch` here.

```{r, message=FALSE, warning=FALSE}
res <- process_z(z_snp_subset, 
                 region_info, 
                 gwas_n,
                 drop_multiallelic = TRUE,
                 drop_strand_ambig = TRUE,
                 detect_ld_mismatch = FALSE)
z_snp <- res$z_snp
```

#### Harmonizing prediction models and LD reference

The `process_weight()` function harmonizes the PredictDB prediction models and LD reference. 
This only needs to be done once per combination of prediction models and LD reference. 

```{r preprocess_weight, message=FALSE, warning=FALSE}
weight <- "/project2/xinhe/kevinluo/cTWAS/ctwas_tutorial/weights/eqtl/mashr/mashr_Liver.db"
res <- process_weight(weight, 
                      region_info, 
                      z_snp,
                      weight_format = "PredictDB",
                      drop_strand_ambig = TRUE,
                      filter_protein_coding_genes = TRUE,
                      scale_by_ld_variance = TRUE)
weight_list <- res$weight_list
weight_info <- res$weight_info
```

### Imputing gene z-scores

```{r impute_expr_z, message=FALSE, warning=FALSE}
res <- compute_gene_z(z_snp_subset, region_info, weight_list, weight_info)
gene_info <- res$gene_info
z_gene_subset <- res$z_gene
```

### Fine-mapping a single locus with fixed parameters

After imputing gene z-scores, we are ready to run the cTWAS analysis. The full analysis involves first estimating parameters from the data, and then fine-mapping the genes and variants using these estimated parameters. This can be computationally intensive, so for this example, we will only run the fine-mapping step at the HPR locus, using the parameters we estimated in the paper.

Let's run the cTWAS fine-mapping step at the HPR locus using the estimated parameters:

```{r finemap_region_L5}
# the estimated prior inclusion probabilities for genes and variants from the paper
group_prior <- c(0.0107220302, 0.0001715896)

# the estimated effect sizes for genes and variants from the paper
group_prior_var <- c(41.327666, 9.977841)

ctwas_res <- finemap_region(z_snp = z_snp_subset,
                            z_gene = z_gene_subset,
                            gene_info = gene_info,
                            region_tag = region_tag,
                            region_info = region_info, 
                            weight_list = weight_list,
                            L = 5,
                            group_prior = group_prior,
                            group_prior_var = group_prior_var,
                            force_compute_cor = TRUE,
                            save_cor = TRUE,
                            cor_dir = "./example_locus_cor/")
```

Finemapping with L = 1, without computing correlation matrices (use a Identity Matrix)
```{r finemap_region_L1}
ctwas_L1_res <- finemap_region(z_snp = z_snp_subset,
                               z_gene = z_gene_subset,
                               gene_info = gene_info,
                               region_tag = region_tag,
                               region_info = region_info, 
                               weight_list = weight_list,
                               L = 1,
                               group_prior = group_prior,
                               group_prior_var = group_prior_var)
```

Finemapping with L = 1, computing correlation matrices

```{r finemap_region_L1_compute_cor}
ctwas_L1_res2 <- finemap_region(z_snp = z_snp_subset,
                                z_gene = z_gene_subset,
                                gene_info = gene_info,
                                region_tag = region_tag,
                                region_info = region_info, 
                                weight_list = weight_list,
                                L = 1,
                                group_prior = group_prior,
                                group_prior_var = group_prior_var,
                                force_compute_cor = TRUE)

all.equal(ctwas_L1_res$susie_pip, ctwas_L1_res2$susie_pip)
all.equal(ctwas_L1_res$mu2, ctwas_L1_res2$mu2)
# all.equal(ctwas_L1_res$cs_index, ctwas_L1_res2$cs_index)
```

## Session information

Here are some details about the computing environment, including the
versions of R, and the R packages, used to generate these results.

```{r}
sessionInfo()
```

